{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AugMix_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dupsys/SlangDict/blob/master/AugMix_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCh-Kf5L1BOj",
        "colab_type": "code",
        "outputId": "e2ca2e36-58d3-4171-c5eb-3252c0194c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "%tensorflow_version 2.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.0`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcG2d_kA1VVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask as dd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsLP__dBUdf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_dim = (32, 32, 3)\n",
        "IMAGE_SIZE = img_dim[0]\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_mnZRQQ0nfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(np.float32) / 255.\n",
        "x_test = x_test.astype(np.float32) / 255.\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_classes).astype(np.float32)\n",
        "y_test_cat = to_categorical(y_test, num_classes=num_classes).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsFfTN_-3gtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_parameter(level, maxval):\n",
        "    \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "    Args:\n",
        "        level: Level of the operation that will be in [0, `PARAMETER_MAX`].\n",
        "        maxval: Maximum value that the operation can have. This will be \n",
        "                scaled to level/PARAMETER_MAX.\n",
        "    Returns:\n",
        "        An int that results from scaling `maxval` according to `level`.\n",
        "    \"\"\"\n",
        "    return int(level * maxval / 10)\n",
        "\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "    \"\"\"Helper function to scale `val` between 0 and maxval.\n",
        "    Args:\n",
        "        level: Level of the operation that will be in [0, `PARAMETER_MAX`].\n",
        "        maxval: Maximum value that the operation can have. This will be \n",
        "                scaled to level/PARAMETER_MAX.\n",
        "    Returns:\n",
        "        A float that results from scaling `maxval` according to `level`.\n",
        "    \"\"\"\n",
        "    return float(level) * maxval / 10.\n",
        "\n",
        "\n",
        "def sample_level(n):\n",
        "    return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "    return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "    return ImageOps.equalize(pil_img)\n",
        "\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), 4)\n",
        "    return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "    degrees = int_parameter(sample_level(level), 30)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        degrees = -degrees\n",
        "    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), 256)\n",
        "    return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 0.3)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                            Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
        "                            resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 0.3)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                            Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
        "                            resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "    if np.random.random() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                            Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
        "                            resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "    if np.random.random() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                            Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
        "                            resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def apply_op(image, op, severity):\n",
        "    image = np.clip(image * 255., 0, 255).astype(np.uint8)\n",
        "    pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
        "    pil_img = op(pil_img, severity)\n",
        "    return np.asarray(pil_img, dtype=np.float32) / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4yKCZvJoGEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmentations = [autocontrast, \n",
        "                    equalize, \n",
        "                    posterize, \n",
        "                    rotate, \n",
        "                    solarize, \n",
        "                    shear_x, \n",
        "                    shear_y,\n",
        "                    translate_x, \n",
        "                    translate_y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKZd-4NSoEET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_and_mix(image, severity=3, width=3, depth=-1, alpha=1.):\n",
        "    \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "    Args:\n",
        "        image: Raw input image as ndarray shape (h, w, c)\n",
        "        severity: Severity of underlying augmentation operators (1-10).\n",
        "        width: Width of augmentation chain\n",
        "        depth: Depth of augmentation chain. -1 or (1, 3)\n",
        "        alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
        "    Returns:\n",
        "        mixed: Augmented and mixed image.\n",
        "    \"\"\"\n",
        "    ws = np.random.dirichlet([alpha] * width).astype(np.float32)\n",
        "    m  = np.random.beta(alpha, alpha)\n",
        "    mix = np.zeros_like(image).astype(np.float32)\n",
        "\n",
        "    for i in range(width):\n",
        "        image_aug = image.copy()\n",
        "        depth = depth if depth > 0 else np.random.randint(1, 4)\n",
        "        for _ in range(depth):\n",
        "            op = np.random.choice(augmentations)\n",
        "            image_aug = apply_op(image_aug, op, severity)\n",
        "            # Preprocessing commutes since all coefficients are convex\n",
        "            mix += ws[i] * image_aug\n",
        "\n",
        "    # mix the image and return \n",
        "    mixed = (1 - m)*image + m*mix\n",
        "    return mixed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1gFXDjYg-br",
        "colab_type": "code",
        "outputId": "e0c7bc66-e13d-4d4a-9700-456824c3dce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "f, ax = plt.subplots(4, 3, figsize=(8,8))\n",
        "for i in range(4):\n",
        "    idx = np.random.randint(1000)\n",
        "    orig = x_train[idx]\n",
        "    aug1 = augment_and_mix(orig)\n",
        "    aug2 = augment_and_mix(orig)\n",
        "    orig = np.clip(orig*255., 0, 255.).astype(np.uint8)\n",
        "    aug1 = np.clip(aug1*255., 0, 255.).astype(np.uint8)\n",
        "    aug2 = np.clip(aug2*255., 0, 255.).astype(np.uint8)\n",
        "    ax[i, 0].imshow(orig)\n",
        "    ax[i, 1].imshow(aug1)\n",
        "    ax[i, 2].imshow(aug2)\n",
        "    ax[i, 0].axis('off')\n",
        "    ax[i, 1].axis('off')\n",
        "    ax[i, 2].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAHBCAYAAAA8SS9SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbl0VP_d244P",
        "colab_type": "text"
      },
      "source": [
        "## Resnet20 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YHXdmYyiYKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version = 1\n",
        "n = 3\n",
        "depth = n * 6 + 2\n",
        "\n",
        "###########################################################################\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = layers.Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = layers.Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = layers.BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = layers.Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "##########################################################################\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = layers.add([x, y])\n",
        "            x = layers.Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = layers.AveragePooling2D(pool_size=8)(x)\n",
        "    y = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.5)(y)\n",
        "    outputs = layers.Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"resnet\"+str(depth))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHGseoqb-Ug7",
        "colab_type": "code",
        "outputId": "bdb670e7-02f9-4fbf-a4f1-9534135dcaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "model = resnet_v1(input_shape, depth)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet20\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 16)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 16)   2320        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 32, 32, 16)   0           activation_19[0][0]              \n",
            "                                                                 batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 16)   2320        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 16)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2320        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 16)   0           activation_21[0][0]              \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 16)   2320        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 16)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 16)   2320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 16)   0           activation_23[0][0]              \n",
            "                                                                 batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 16)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 32)   4640        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 32)   9248        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 32)   544         activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 16, 16, 32)   0           conv2d_30[0][0]                  \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 32)   0           activation_27[0][0]              \n",
            "                                                                 batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 32)   0           activation_29[0][0]              \n",
            "                                                                 batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 64)     18496       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 64)     256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 64)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     36928       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     2112        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 64)     0           conv2d_37[0][0]                  \n",
            "                                                                 batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           activation_33[0][0]              \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_35[0][0]              \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1vD4zr9Gx-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss function to be used for training\n",
        "kld = tf.keras.losses.KLDivergence()\n",
        "entropy = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "def jsd_loss_fn(y_true, y_pred_clean, y_pred_aug1, y_pred_aug2):\n",
        "    # cross entropy loss that is used for clean images only\n",
        "    loss = entropy(y_true, y_pred_clean)\n",
        "\n",
        "    mixture = (y_pred_clean + y_pred_aug1 + y_pred_aug2) / 3.\n",
        "    mixture = tf.math.log(tf.clip_by_value(mixture, 1e-7, 1.))\n",
        "\n",
        "    loss += 12. * (kld(mixture, y_pred_clean) + \n",
        "                    kld(mixture, y_pred_aug1) +\n",
        "                    kld(mixture, y_pred_aug2)) / 3.\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfu-omBsKhFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_epochs = 100\n",
        "batch_size = 128\n",
        "nb_train_steps = int(np.ceil(len(x_train) / batch_size))\n",
        "nb_test_steps = int(np.ceil(len(x_test) / batch_size))\n",
        "train_indices = np.arange(len(x_train))\n",
        "test_indices = np.arange(len(x_test))\n",
        "\n",
        "lr_max = 1.0\n",
        "lr_min = 1e-5\n",
        "total_steps = nb_train_steps\n",
        "\n",
        "\n",
        "# learning rate scheduler\n",
        "def get_lr(step):\n",
        "  \"\"\"Compute learning rate according to cosine annealing schedule.\"\"\"\n",
        "  return lr_min + (lr_max - lr_min) * 0.5 * (1 +\n",
        "                                             np.cos(step / total_steps * np.pi))\n",
        "\n",
        "# Define the optimizer with the lr scheduler\n",
        "optim = optimizers.SGD(learning_rate=get_lr(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLcqzxvfTsmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train data generator \n",
        "def train_data_generator(data, labels, curr_batch):\n",
        "    batch_len = len(curr_batch)\n",
        "    X_orig = np.zeros((batch_len, *img_dim), dtype=np.float32)\n",
        "    X_aug1 = np.zeros((batch_len, *img_dim), dtype=np.float32)\n",
        "    X_aug2 = np.zeros((batch_len, *img_dim), dtype=np.float32)\n",
        "    y = np.zeros((batch_len, num_classes), dtype=np.float32)\n",
        "\n",
        "    for i, idx in enumerate(curr_batch):\n",
        "        img = data[idx]\n",
        "        X_orig[i] = augment_and_mix(img)\n",
        "        X_aug1[i] = augment_and_mix(img)\n",
        "        X_aug2[i] = augment_and_mix(img)\n",
        "        y[i] = labels[idx]\n",
        "\n",
        "    return [X_orig, X_aug1, X_aug2], y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa9kGXyx3LKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train(clean, aug1, aug2, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # get predictions on clean images\n",
        "        y_pred_clean = model(clean, training=True)\n",
        "        \n",
        "        # get predictions on augmented images\n",
        "        y_pred_aug1 = model(aug1, training=True)\n",
        "        y_pred_aug2 = model(aug2, training=True)\n",
        "\n",
        "        # calculate loss\n",
        "        loss_value = jsd_loss_fn(y_true = labels, \n",
        "                            y_pred_clean = y_pred_clean,\n",
        "                            y_pred_aug1 = y_pred_aug1,\n",
        "                            y_pred_aug2 = y_pred_aug2)\n",
        "        \n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optim.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    return loss_value, y_pred_clean\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def validate(images, labels):\n",
        "    y_pred = model(images, training=False)\n",
        "    loss = entropy(labels, y_pred)\n",
        "    return loss, y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfDh-TdTLqPf",
        "colab_type": "code",
        "outputId": "eef14cf5-6a27-4868-eaf8-757b7560e745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# metric to keep track of \n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "    np.random.shuffle(train_indices)\n",
        "    \n",
        "    # Train for an epoch and keep track of \n",
        "    # loss and accracy for each batch.\n",
        "    for bno in range(nb_train_steps):\n",
        "        # Get the indices for this batch\n",
        "        indices = train_indices[bno*batch_size:(bno + 1)*batch_size]  \n",
        "        batch_data = dd.delayed(train_data_generator)(x_train, y_train_cat, indices)\n",
        "\n",
        "        # Get the batch data \n",
        "        images, labels = batch_data.compute(num_workers=4)\n",
        "        clean, aug1, aug2 = images\n",
        "        loss_value, y_pred_clean = train(clean, aug1, aug2, labels)\n",
        "\n",
        "        # Record batch loss and batch accuracy\n",
        "        train_loss(loss_value)\n",
        "        train_accuracy(labels, y_pred_clean)\n",
        "\n",
        "\n",
        "    \n",
        "    # Validate after each epoch\n",
        "    for bno in range(nb_test_steps):\n",
        "        # Get the indices for the current batch\n",
        "        indices = test_indices[bno*batch_size:(bno + 1)*batch_size]\n",
        "        \n",
        "        # Get the data \n",
        "        images, labels = x_test[indices], y_test_cat[indices]\n",
        "\n",
        "        # Get the predicitions and loss for this batch\n",
        "        loss_value, y_pred = validate(images, labels)\n",
        "\n",
        "        # Record batch loss and accuracy\n",
        "        test_loss(loss_value)\n",
        "        test_accuracy(labels, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "    # print loss values and accuracy values for each epoch \n",
        "    # for both training as well as validation sets\n",
        "    print(f\"\"\"Epoch: {epoch} \n",
        "            train_loss: {train_loss.result():.6f}  train_acc: {train_accuracy.result():.3f}   \n",
        "             test_loss: {test_loss.result():.6f}   test_acc: {test_accuracy.result():.3f}\"\"\")\n",
        "              \n",
        "    \n",
        "    # Reset the losses and accuracy\n",
        "    train_loss.reset_states() \n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states() \n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \n",
            "            train_loss: 2.215591  train_acc: 0.195   \n",
            "             test_loss: 2.580989   test_acc: 0.184\n",
            "Epoch: 1 \n",
            "            train_loss: 1.703007  train_acc: 0.362   \n",
            "             test_loss: 1.922286   test_acc: 0.322\n",
            "Epoch: 2 \n",
            "            train_loss: 1.419781  train_acc: 0.481   \n",
            "             test_loss: 2.590132   test_acc: 0.319\n",
            "Epoch: 3 \n",
            "            train_loss: 1.235001  train_acc: 0.554   \n",
            "             test_loss: 1.361395   test_acc: 0.520\n",
            "Epoch: 4 \n",
            "            train_loss: 1.096852  train_acc: 0.610   \n",
            "             test_loss: 1.109309   test_acc: 0.608\n",
            "Epoch: 5 \n",
            "            train_loss: 0.985037  train_acc: 0.651   \n",
            "             test_loss: 1.226719   test_acc: 0.591\n",
            "Epoch: 6 \n",
            "            train_loss: 0.892169  train_acc: 0.687   \n",
            "             test_loss: 1.062315   test_acc: 0.629\n",
            "Epoch: 7 \n",
            "            train_loss: 0.818524  train_acc: 0.712   \n",
            "             test_loss: 1.303059   test_acc: 0.590\n",
            "Epoch: 8 \n",
            "            train_loss: 0.761358  train_acc: 0.733   \n",
            "             test_loss: 1.239424   test_acc: 0.610\n",
            "Epoch: 9 \n",
            "            train_loss: 0.710137  train_acc: 0.750   \n",
            "             test_loss: 0.933989   test_acc: 0.683\n",
            "Epoch: 10 \n",
            "            train_loss: 0.665457  train_acc: 0.767   \n",
            "             test_loss: 1.074716   test_acc: 0.643\n",
            "Epoch: 11 \n",
            "            train_loss: 0.632003  train_acc: 0.778   \n",
            "             test_loss: 0.803061   test_acc: 0.725\n",
            "Epoch: 12 \n",
            "            train_loss: 0.597606  train_acc: 0.792   \n",
            "             test_loss: 0.743300   test_acc: 0.749\n",
            "Epoch: 13 \n",
            "            train_loss: 0.570429  train_acc: 0.802   \n",
            "             test_loss: 1.042954   test_acc: 0.688\n",
            "Epoch: 14 \n",
            "            train_loss: 0.541884  train_acc: 0.813   \n",
            "             test_loss: 0.843319   test_acc: 0.731\n",
            "Epoch: 15 \n",
            "            train_loss: 0.513923  train_acc: 0.821   \n",
            "             test_loss: 1.464325   test_acc: 0.613\n",
            "Epoch: 16 \n",
            "            train_loss: 0.494511  train_acc: 0.828   \n",
            "             test_loss: 1.541211   test_acc: 0.563\n",
            "Epoch: 17 \n",
            "            train_loss: 0.470705  train_acc: 0.835   \n",
            "             test_loss: 0.775423   test_acc: 0.743\n",
            "Epoch: 18 \n",
            "            train_loss: 0.454662  train_acc: 0.841   \n",
            "             test_loss: 1.031870   test_acc: 0.694\n",
            "Epoch: 19 \n",
            "            train_loss: 0.434064  train_acc: 0.848   \n",
            "             test_loss: 0.930668   test_acc: 0.724\n",
            "Epoch: 20 \n",
            "            train_loss: 0.422484  train_acc: 0.853   \n",
            "             test_loss: 0.672051   test_acc: 0.783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3a5bc97b86f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Get the batch data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     results = get_async(pool.apply_async, len(pool._pool), dsk, result,\n\u001b[1;32m     75\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_thread_get_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                         pack_exception=pack_exception, **kwargs)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# Cleanup pools associated to dead threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'waiting'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ready'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'running'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DYulXvOApxs",
        "colab_type": "text"
      },
      "source": [
        "## References:\n",
        "Original paper Augmix: https://arxiv.org/pdf/1912.02781.pdf <br>\n",
        "Original Pytorch implementation: https://github.com/google-research/augmix/blob/master/cifar.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5FoDBAMg_vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}