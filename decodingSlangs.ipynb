{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, RepeatVector, TimeDistributed, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abbreviation, meaning = list(zip(*[(key, value) for key, value in {\n",
    "    'ao': 'adult only',\n",
    "    'u': 'you',\n",
    "    'gf': 'girl friend',\n",
    "    'sul': 'see you later'\n",
    "#   'tmi': 'too much information'\n",
    "}.iteritems()]))\n",
    "\n",
    "# abbreviation, meaning = list(zip(*[tuple(s.split()) for s in [\n",
    "#     'gf': 'girl friend',\n",
    "#     'sul': 'see you later',\n",
    "#     '2mor': 'tomorrow',\n",
    "#     'tmi': 'too much information']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 13, '# adefgilnorstuy')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the symbol alphabet, including the padding symbol '#'\n",
    "letters = '#'  +''.join(sorted({c for s in abbreviation+meaning for c in s}))\n",
    "\n",
    "# Map from letters to indexes\n",
    "letter_index = {c:i for i,c in enumerate(letters)}\n",
    "\n",
    "# Compute the size of our alphabet\n",
    "n_letters = len(letters)\n",
    "nb_filters=10\n",
    "\n",
    "# Compute the maximum string length\n",
    "max_length = max(map(len, abbreviation+meaning))\n",
    "\n",
    "n_letters, max_length, letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "From now on, we need to work with numerical types rather than unicode strings.\n",
    "So, we define functions to convert between lists of integers and strings using our dataset:\n",
    "'''\n",
    "def encode_string(s): \n",
    "    return [letter_index[c] for c in s]\n",
    "def decode_string(a): \n",
    "    return ''.join(letters[i] for i in a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array([ 6,  7, 11,  8,  1,  5, 11,  7,  4,  9,  3,  0,  0], dtype=int32),\n",
       " 'gf###########',\n",
       " 'girl friend##')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For efficiency reasons all computations will be done using dense matrices. Since we deal with strings of different\n",
    "length we need to pad them into dense rectangular matrices. While this results in some unneccesary computation, \n",
    "it is well worth the increased speed of dense matrix operations (especially on a GPU). \n",
    "Keras has the helper function pad_sequences for this purpose.\n",
    "'''\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def encode_and_pad(words):\n",
    "    return pad_sequences(list(map(encode_string, words)), padding='post', maxlen=max_length)\n",
    "\n",
    "# Our inputs (x) will be the participles\n",
    "padded_x = encode_and_pad(abbreviation)\n",
    "\n",
    "# And the outputs (y) will be the canonial forms of the abbreviation\n",
    "padded_y = encode_and_pad(meaning)\n",
    "\n",
    "# As in the previous output, but with the padding.\n",
    "padded_x[0], padded_y[0], decode_string(padded_x[0]), decode_string(padded_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constructing the Model now\n",
    "\n",
    "# 1st keras requires to specify the maximum length of input sequences, \n",
    "# So, we use the number of columns from our padded_x matrix.\n",
    "word = Input((max_length,))\n",
    "\n",
    "# Letters are represented by 32-dimensional embeddings covering the alphabet (of n_letters).\n",
    "embedded_word = Embedding(32, n_letters, mask_zero=False)(word)\n",
    "\n",
    "# Our LSTM encoder will produce a 128-dimensional vector as output.\n",
    "encoding = LSTM(128)(embedded_word)\n",
    "\n",
    "# Repeat the encoding over the length of the output string.\n",
    "repeated_encoding = RepeatVector(max_length)(encoding)\n",
    "\n",
    "# We concatenate the repeated encoding with the embedded input string (in the last dimension).\n",
    "merged_encoding = merge([repeated_encoding, embedded_word], mode='concat')\n",
    "\n",
    "# Our LSTM decoder will produce a _sequence_ of 128-dimensional vectors.\n",
    "decoded = LSTM(128, return_sequences=True)(merged_encoding)\n",
    "\n",
    "# Each of these vectors will be passed through (the same) fully connected layer with softmax activations.\n",
    "# The result is a sequence of distributions over the alphabet.\n",
    "output_word = TimeDistributed(Dense(n_letters, activation='softmax'))(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "model = Model(input=word, output=output_word)\n",
    "# Here optimization algorithm called 'adam' was a good default choice to use and for loss function.\n",
    "# The goal is to make the output distributions as close as possible to the values in the training set,\n",
    "# so we use categorical cross-entropy loss.\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.], dtype=float32), 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_y_dist = np.zeros(padded_y.shape+(n_letters,), dtype=np.float32)\n",
    "for i,row in enumerate(padded_y):\n",
    "    for j,letter in enumerate(row):\n",
    "        padded_y_dist[i,j,letter] = True\n",
    "\n",
    "# Note that all elements are zero except the one at the position of 'r' in our alphabet \n",
    "# (this is the first letter of 'running')\n",
    "padded_y_dist[0,0], padded_y_dist[0,0,letter_index['r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40.61 seconds'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "history = model.fit(padded_x, padded_y_dist, nb_epoch=200, verbose=0)\n",
    "'%.2f seconds' % (time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['girl friend', 'see you later', 'you', 'adult only']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_and_decode(x):\n",
    "    predicted_y = model.predict(x)\n",
    "    return [decode_string(row.argmax(axis=-1)).replace(\"#\",'') for row in predicted_y]\n",
    "\n",
    "# Do predictions on the training set.\n",
    "predict_and_decode(padded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adult only', 'see you later', 'you']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_and_decode(encode_and_pad(['ao','sul','u']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', ' ', 'w', 'l', 's', 'e', 'y', 'o', 'u', 't', 'm', 'r', ',', 'p', 'a', 'b', 'f', 'c', 'd', 'n', '.', 'T', 'h', 'k', 'R', 'g'] 26\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "raw_text='i will see you tomorrow, please be prepare for me because i dont want to be late. Thank you and see you then.Regards to the family'\n",
    "unique = []\n",
    "for char in raw_text[::]:\n",
    "    if char not in unique:\n",
    "        unique.append(char)\n",
    "print(unique), len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 24\n",
      "105 105\n"
     ]
    }
   ],
   "source": [
    "raw_text = raw_text.lower()\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c,i) for i,c in enumerate(chars))\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print n_chars, n_vocab\n",
    "seq_length = 25\n",
    "dataX=[]\n",
    "dataY=[]\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "#     print i\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "# print len(seq_in), len(seq_out)\n",
    "# print seq_in, seq_out\n",
    "    dataX.append(char_to_int[char] for char in seq_in)\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "print len(dataX), len(dataY)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
